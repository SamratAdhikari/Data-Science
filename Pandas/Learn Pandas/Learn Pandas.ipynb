{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fuzzy-auditor",
   "metadata": {},
   "source": [
    "# Pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-lighting",
   "metadata": {},
   "source": [
    "Pandas provides numerous tools to work with tabular data like you'd find in spreadsheets or databases. It is widely used for data preparation, cleaning, and analysis. It can work with a wide variety of data and provides many visualization options. It is built on top of NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-kazakhstan",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "adjacent-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-arrangement",
   "metadata": {},
   "source": [
    "### Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "representative-investment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Series 6'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# series are 1D data structures\n",
    "list1 = ['a', 'b', 'c', 'd'] # data\n",
    "labels = [1, 2, 3, 4]        # labels for data\n",
    "\n",
    "# create table with list\n",
    "series_1 = pd.Series(data=list1, index=labels)\n",
    "series_1\n",
    "\n",
    "# create table with numpy array\n",
    "array = np.array([1, 2, 3, 4])\n",
    "series_2 = pd.Series(array)\n",
    "series_2\n",
    "\n",
    "# create table with dictionary\n",
    "dict_1 = {\"Name\": \"Samrat\", \"Age\": 18, \"Address\": \"Pokhara-5\"}\n",
    "series_3 = pd.Series(dict_1)\n",
    "series_3\n",
    "series_3[\"Name\"]\n",
    "series_3.dtype\n",
    "\n",
    "# Basic Maths operations with series (series must be of same type)\n",
    "series_2 + series_2 # add\n",
    "series_2 - series_2 # substract\n",
    "series_2 * series_2 # multiply\n",
    "series_2 / series_2 # divide\n",
    "\n",
    "# pass series into numpy methods\n",
    "np.exp(series_2) # returns the exponential value in series_2\n",
    "\n",
    "# If we try to operate between two dict-series with different index values, NaN is returned\n",
    "series_4 = pd.Series({4:5, 5:6, 6:7, 7:8})\n",
    "series_2 + series_4\n",
    "\n",
    "# Assign names to series\n",
    "series_5 = pd.Series({1: 2, \"samrat\": 5, \"name\": \"naruto\", 6: \"hinata\"}, name=\"Random Dict\")\n",
    "series_5.name\n",
    "series_6 = pd.Series([1, 2, 3, 4], name=\"Series 6\")\n",
    "series_6.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-chicken",
   "metadata": {},
   "source": [
    "### Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "falling-hybrid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1 = np.random.randint(10, 50, size=(2, 3))\n",
    "array1\n",
    "\n",
    "# create dataframes using array1 along with row and columns\n",
    "pd.DataFrame(array1, [\"A\", \"B\"], [\"C\", \"D\", \"E\"])\n",
    "# [\"A\", \"B\"] == row | [\"C\", \"D\", \"E\"] == column\n",
    "\n",
    "\n",
    "# Create dataframe with multiple series\n",
    "dict2 = {\"one\": pd.Series([1., 2., 3.], index=[\"a\", \"b\", \"c\"]),\n",
    "         \"two\": pd.Series([1., 2., 3., 4.], index=[\"a\", \"b\", \"c\", \"d\"])}\n",
    "dataframe2 = pd.DataFrame(dict2)\n",
    "\n",
    "\n",
    "# Accept column labels and list\n",
    "dict( [ (\"A\", [1, 2, 3]), (\"B\", [4, 5, 6]) ] )\n",
    "pd.DataFrame.from_dict(dict( [ (\"A\", [1, 2, 3]), (\"B\", [4, 5, 6]) ] ))\n",
    "\n",
    "\n",
    "# assign keys as rows label and columns label\n",
    "dataframe = pd.DataFrame.from_dict(dict( [ (\"A\", [1, 2, 3]), (\"B\", [4, 5, 6]) ] ),\n",
    "                      orient='index', columns=[\"one\", \"two\", \"three\"] )\n",
    "\n",
    "\n",
    "# two find no. of rows and columns inside a dataframe\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-campbell",
   "metadata": {},
   "source": [
    "### Edit & Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "middle-idaho",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   one  two  three\n",
      "A    1    2      3\n",
      "B    4    5      6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A\n",
       "0  1.0\n",
       "1  9.0\n",
       "2  3.0\n",
       "3  4.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------Retrieve Data from DataFrame----------------------------\n",
    "print(dataframe)\n",
    "dataframe[\"one\"] # retrieve data from single column as series\n",
    "dataframe[ [\"two\", \"three\"] ] # retrieve data from multiple column as series\n",
    "\n",
    "dataframe.loc['A'] # retrieve data from row as series\n",
    "dataframe.iloc[1]  # retrieve data from row using index position\n",
    "\n",
    "dataframe.loc['A', 'three'] # retrieve specific data from specific row and column\n",
    "dataframe.loc[ ['A', 'B'], ['one', 'three'] ] # data from multiple row and column\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------Edit Data from DataFrame----------------------------\n",
    "\n",
    "\n",
    "# create a new column\n",
    "dataframe['Total'] = dataframe['one'] + dataframe['two'] + dataframe['three']\n",
    "# create new column which stores the summation of data in other columns within a row\n",
    "dataframe['Multi'] = dataframe['one'] * dataframe['two'] * dataframe['three']\n",
    "# create new column with stores the multiplication of data in other columns within a row\n",
    "dataframe\n",
    "\n",
    "\n",
    "# create new row\n",
    "# dict3 = {'one': 5, 'two': 6, 'three': 7}\n",
    "# new_row = pd.Series(dict3, name='C')\n",
    "# dataframe = dataframe.append(new_row)\n",
    "# dataframe\n",
    "\n",
    "\n",
    "# delete a dataframe column\n",
    "dataframe.drop('Multi', axis=1, inplace=True)  # axis = 1 denotes columns\n",
    "# other way of deleting column\n",
    "# del dataframe['E'] # single column\n",
    "# del dataframe['D', 'F'] # multiple column\n",
    "\n",
    "\n",
    "# delete a dataframe column\n",
    "# dataframe = dataframe.drop('C', axis=0, inplace=True)  # axis = 0 denotes row\n",
    "# dataframe = dataframe.drop(['F', 'G']) # multiple row\n",
    "\n",
    "\n",
    "# create a new column and make it the index (in place of A, B and C)\n",
    "# dataframe['Sex'] = ['Man', 'Woman']\n",
    "# dataframe.set_index('Sex', inplace=True)\n",
    "\n",
    "\n",
    "# reset index values ro numbers\n",
    "# dataframe.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "# use assign to create a column while leaving the original dataframe untouched\n",
    "dataframe2.assign(div=dataframe2['one'] / dataframe2['two'])\n",
    "# another way of doing it\n",
    "dataframe2.assign(multi=lambda x: (x['one'] * x['two']))\n",
    "\n",
    "\n",
    "# combine dataframes\n",
    "dataframe3 = pd.DataFrame( {'A': [1., np.nan, 3., np.nan]} )\n",
    "dataframe4 = pd.DataFrame( {'A': [8., 9., 2., 4.]} )\n",
    "dataframe3.combine_first(dataframe4)\n",
    "# keeps the values of dataframe3 and replaces corresponding elements from dataframe4 \n",
    "# incase there are NaN values in dataframe3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-virtue",
   "metadata": {},
   "source": [
    "### Conditional Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hollow-ticket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    C   D   E\n",
      "A  28  27  22\n",
      "B  38  30  20\n",
      "   X  Y  Z\n",
      "A  1  2  3\n",
      "B  4  5  6\n",
      "C  7  8  9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X  Y  Z\n",
       "B  4  5  6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array2 = np.random.randint(10, 50, size=(2, 3))\n",
    "dataframe5 = pd.DataFrame(array2, ['A', 'B'], ['C', 'D', 'E'])\n",
    "print(dataframe5)\n",
    "\n",
    "\n",
    "# Returns True or False according to condition applied\n",
    "dataframe5 > 40   # Returns True if the data are greater than 40 else returns False\n",
    "dataframe5.gt(40) # another way of doing it\n",
    "dataframe5 <= 40  # smaller than or equal to\n",
    "dataframe5 != 40  # not equal to\n",
    "dataframe5 == 40  # equal to\n",
    "# gt - greater than\n",
    "# lt - less than\n",
    "# ge - greater than or equal to\n",
    "# le - less than or equal to\n",
    "# eq - equal to\n",
    "# ne - not equal to\n",
    "\n",
    "\n",
    "# returns only the true values else returns NaN\n",
    "bool1 = dataframe5 <= 45\n",
    "dataframe5[bool1]\n",
    "\n",
    "\n",
    "# compare a specific column\n",
    "dataframe5['C'] < 40\n",
    "# returns True or False if the data in column C is smaller than 40 or not\n",
    "dataframe5[['C', 'D']]  < 40 # multiple columns\n",
    "\n",
    "\n",
    "# compare a specific row\n",
    "dataframe5[ dataframe5['E'] > 30 ]\n",
    "# returns the row if the value in column 'E' is greater than 30\n",
    "dataframe5[ dataframe5[['C', 'E']] > 30 ] # for mutiple rows\n",
    "\n",
    "\n",
    "# stack the commands\n",
    "dataframe5[ dataframe5['E'] > 20 ]['C']\n",
    "# get the row where data in column E is greater than 20 and get the column C from that row\n",
    "\n",
    "\n",
    "# use multiple different conditions\n",
    "array3 = np.array([ [1, 2, 3], [4, 5, 6], [7, 8, 9] ])\n",
    "dataframe6 = pd.DataFrame(array3, ['A', 'B', 'C'], ['X', 'Y', 'Z'])\n",
    "print(dataframe6)\n",
    "# use array3 as the datasets, ['A', 'B', 'C'] as rows and ['X', 'Y', 'Z'] as columns label\n",
    "dataframe6[ (dataframe6['X']>3) & (dataframe6['X']<7) ] \n",
    "# returns the row in which the data in column X is greater than 3 and smaller than 7\n",
    "# for OR, use | instead of &"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-confirmation",
   "metadata": {},
   "source": [
    "### File Input & Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-endorsement",
   "metadata": {},
   "source": [
    "Pandas can work with the following types of data : CSV, Plain Text, JSON, XML, PDF, SQL, HTML, XLSX, DOCX, ZIP, Images Hierarchical Data Format, MP3, and MP4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "catholic-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from a csv file\n",
    "csDF = pd.read_csv('ComputerSales.csv')\n",
    "csDF\n",
    "\n",
    "# save it as csv file\n",
    "csDF.to_csv('csv_ComputerSales.csv')\n",
    "\n",
    "# read excel file\n",
    "pd.read_excel('Financial Sample.xlsx')\n",
    "\n",
    "# save the file as excel (.xlsx) file\n",
    "csDF.to_excel('excel_ComputerSales.xlsx')\n",
    "\n",
    "# read the saved excel file\n",
    "pd.read_excel('excel_ComputerSales.xlsx')\n",
    "\n",
    "# get one column worth of data from csv\n",
    "pd.read_csv('ComputerSales.csv', usecols=['Sex'])\n",
    "pd.read_csv('ComputerSales.csv', usecols=['Sex', 'Contact']) # for multiple columns\n",
    "\n",
    "\n",
    "# --------------------Working with Database-------------------\n",
    "\n",
    "# connect with database\n",
    "try:\n",
    "    db_conn = pymysql.connect(db='learnsql', user='root', passwd='samrat@123#',\n",
    "                              host='localhost', port=3306)\n",
    "    studentDF = pd.read_sql('SELECT * FROM sample_students', con=db_conn)\n",
    "#     print(studentDF)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Exception: \\n\" + str(e))\n",
    "    \n",
    "finally:\n",
    "    db_conn.close()\n",
    "    \n",
    "\n",
    "# Insert data into database\n",
    "try:\n",
    "    db_conn = pymysql.connect(db='learnsql', user='root', passwd='samrat@123#',\n",
    "                              host='localhost', port=3306)\n",
    "    cursor = db_conn.cursor()\n",
    "    insertData = \"INSERT INTO sample_students VALUES(20060106, 'Adhikari', 'Samrat')\"\n",
    "    cursor.execute(insertData)\n",
    "    db_conn.commit()\n",
    "    \n",
    "    studentDF = pd.read_sql('SELECT * FROM sample_students', con=db_conn)\n",
    "    # print(studentDF)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Exception: \\n\" + str(e))\n",
    "    \n",
    "finally:\n",
    "    db_conn.close()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-reputation",
   "metadata": {},
   "source": [
    "### Maths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "after-convergence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   one  two\n",
      "a  1.0  1.0\n",
      "b  2.0  0.0\n",
      "c  3.0  3.0\n",
      "d  0.0  4.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     one    two\n",
       "a  False  False\n",
       "b  False  False\n",
       "c  False  False\n",
       "d  False  False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting specific rows\n",
    "csDF.head()  # to get first 5 results\n",
    "csDF.tail()  # to get last 5 results\n",
    "csDF[:2]     # to get first 2 results\n",
    "csDF[3:16:2] # to result from 3rd to 15th row skipping 1 row at a time\n",
    "\n",
    "# get index of the rows in dataframe\n",
    "csDF.index.array \n",
    "\n",
    "# convert the dataframe to numpy array\n",
    "csDF.to_numpy()\n",
    "\n",
    "# convert our series to an array\n",
    "series_1.array\n",
    "\n",
    "\n",
    "# New Dataframe\n",
    "dict4 = { 'one': pd.Series([1, 2, 3], index=['a', 'b', 'c']),\n",
    "          'two': pd.Series([1, np.nan, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "        }\n",
    "# create the dataframe\n",
    "dataframe7 = pd.DataFrame(dict4)\n",
    "dataframe7\n",
    "\n",
    "# replace NaN values inside dataframe\n",
    "dataframe7.fillna(0, inplace=True) #inplace=True replaces the value permanently\n",
    "\n",
    "# get the values in row 2\n",
    "row = dataframe7.iloc[1]\n",
    "# add values of row 2 to all the rows including row 2 (x = x + 1)\n",
    "dataframe7.add(row, axis='columns')\n",
    "\n",
    "# get the values in column two\n",
    "col = dataframe7['two']\n",
    "# sub values of column 'two' to all the columns including column two\n",
    "dataframe7.sub(col, axis=0)\n",
    "\n",
    "# to check if our dataframe is empty\n",
    "dataframe7.empty\n",
    "\n",
    "# transform: execute a function on a dataframe\n",
    "dataframe8 = pd.DataFrame( { 'A': range(3), 'B': range(1, 4) } )\n",
    "\n",
    "# add 1 to every single value in dataframe\n",
    "dataframe8.transform(lambda x: x+1)\n",
    "\n",
    "# square all the value in dataframe\n",
    "dataframe8.transform(lambda x: x**2)\n",
    "\n",
    "# square root all the values in dataframe\n",
    "dataframe8.transform(lambda x: np.sqrt(x))\n",
    "\n",
    "# use multiple lambda functions\n",
    "dataframe8.transform( [lambda x: [x**3,  x + 1]] )\n",
    "dataframe8.transform( [np.sqrt, np.exp] )\n",
    "\n",
    "# assign two different functions to two different columns\n",
    "dataframe8.transform( {'A': lambda x: x**2, 'B': lambda x: x**3 } )\n",
    "\n",
    "# using map function\n",
    "dataframe8['A'].map(lambda x: x**4)\n",
    "# another way of doing it, but for all columns\n",
    "dataframe8.applymap(lambda x: x**4)\n",
    "\n",
    "# get unique values\n",
    "print(dataframe7)\n",
    "dataframe7.loc['c'].unique() # from row\n",
    "dataframe7['two'].unique()   # from column\n",
    "\n",
    "# get no of unique values\n",
    "dataframe7.loc['c'].nunique() # from row\n",
    "dataframe7['two'].nunique()   # from column\n",
    "\n",
    "# find the no of times a value showed up\n",
    "dataframe7['two'].value_counts()\n",
    "\n",
    "# get columns name\n",
    "dataframe7.columns\n",
    "\n",
    "# get row name (index)\n",
    "dataframe7.index\n",
    "\n",
    "# check if the dataframe contains any null values\n",
    "dataframe7.isnull() # returns True if there are any null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-substance",
   "metadata": {},
   "source": [
    "### Group Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "according-failing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sales                                              \n",
       "      count  mean       std   min   25%   50%   75%   max\n",
       "Store                                                    \n",
       "1       2.0  22.0  5.656854  18.0  20.0  22.0  24.0  26.0\n",
       "2       2.0  17.0  7.071068  12.0  14.5  17.0  19.5  22.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict5 = {'Store': [1, 2, 1, 2], 'Flavor': ['Choc', 'Van', 'Straw', 'Choc'],\n",
    "        'Sales': [26, 12, 18, 22]}\n",
    "dataframe9 = pd.DataFrame(dict5)\n",
    "dataframe9\n",
    "\n",
    "\n",
    "# group data by store number\n",
    "byStore = dataframe9.groupby('Store')\n",
    "# groupby - group rows based off of columns and perform a function that combines that values\n",
    "# a function that combines values is called an aggregate function\n",
    "\n",
    "byStore.mean() # get mean values in sales for both of the stores\n",
    "byStore.sum()  # get sum of sales for each store (26+18) and (12+22)\n",
    "byStore.sum().loc[1] # get the sum of sales for store 1 only\n",
    "\n",
    "\n",
    "# get whole bunch of data with describe function\n",
    "byStore.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-numbers",
   "metadata": {},
   "source": [
    "### Concatenate, Merge & Join Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "informed-linux",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C     D\n",
       "1  1.0  4.0  7.0  10.0\n",
       "2  2.0  5.0  NaN   NaN\n",
       "3  3.0  6.0  NaN   NaN\n",
       "4  NaN  NaN  8.0  11.0\n",
       "5  NaN  NaN  9.0  12.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatinate two dataframes (add/ stack two dataframes with different indexes)\n",
    "dataframe10 = pd.DataFrame( {'A': [1, 2, 3], 'B': [4, 5, 6]}, index=[1, 2, 3] )\n",
    "dataframe11 = pd.DataFrame( {'A': [7, 8, 9], 'B': [10, 11, 12]}, index=[4, 5, 6] )\n",
    "\n",
    "pd.concat([dataframe10, dataframe11])\n",
    "\n",
    "\n",
    "# merge two dataframes using their shared key column\n",
    "dataframe12 = pd.DataFrame( {'A': [1, 2, 3], 'B': [4, 5, 6],    'key':[1, 2, 3]} )\n",
    "dataframe13 = pd.DataFrame( {'A': [7, 8, 9], 'B': [10, 11, 12], 'key':[1, 2, 3]} )\n",
    "\n",
    "pd.merge(dataframe12, dataframe13, how='inner', on='key') # keys must me same \n",
    "# inner-joint = intersection of our keys\n",
    "pd.merge(dataframe12, dataframe13, how='right', on='key')\n",
    "pd.merge(dataframe12, dataframe13, how='left', on='key')\n",
    "pd.merge(dataframe12, dataframe13, how='outer', on='key') # union of the keys\n",
    "\n",
    "\n",
    "# join two dataframes (instead of using keys, we will use columns but we will write index)\n",
    "dataframe14 = pd.DataFrame( {'A': [1, 2, 3], 'B': [4, 5, 6]},    index=[1, 2, 3] )\n",
    "dataframe15 = pd.DataFrame( {'C': [7, 8, 9], 'D': [10, 11, 12]}, index=[1, 4, 5] )\n",
    "\n",
    "dataframe14.join(dataframe15, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-asthma",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "induced-auckland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   one  two\n",
      "a  1.0  1.0\n",
      "b  2.0  2.0\n",
      "c  3.0  3.0\n",
      "d  NaN  4.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.290994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      one       two\n",
       "mean  2.0  2.500000\n",
       "std   1.0  1.290994"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iceDF = pd.read_csv('icecreamsales.csv')\n",
    "iceDF\n",
    "\n",
    "# total count of both of the columns (temperature and sales)\n",
    "iceDF.count()\n",
    "\n",
    "# sum the column values\n",
    "iceDF.sum()\n",
    "iceDF.sum(skipna=True) # to skip any NaN values\n",
    "\n",
    "# -------------------Statistic Functions--------------\n",
    "\n",
    "iceDF['Sales'].mean()   # get mean for the sales column\n",
    "iceDF['Sales'].median() # get median for the sales column\n",
    "iceDF['Sales'].mode()   # get mode for the sales column\n",
    "iceDF['Sales'].min()    # get min value from the sales column\n",
    "iceDF['Sales'].max()    # get max value from the sales column\n",
    "iceDF['Sales'].sum()    # get sum of all the data from the sales column\n",
    "iceDF['Sales'].product()# get product of all the data from the sales column\n",
    "iceDF['Sales'].std()    # get standard deviation of the data from the sales column\n",
    "iceDF['Sales'].var()    # get variance of the data from the sales column\n",
    "iceDF['Sales'].sem()    # get standard error from the data from the sales column\n",
    "iceDF['Sales'].skew()   # to find out how much biased (asymmetrical) the data are\n",
    "# if skew value is +ve, the data has long tail to the right (asymmetry to the right)\n",
    "# if skew value is -ve, the data has long tail to the left  (asymmetry to the left)\n",
    "# if skew value is 0,   the data is symmetrical\n",
    "\n",
    "iceDF['Sales'].kurt()   # short for kurtosis\n",
    "# it tells how many outlier we have in our data\n",
    "# <3, that means we have few outliers\n",
    "# at 3, that means we have a normal distribution\n",
    "# >3, that means we have a lot of outliers\n",
    "\n",
    "iceDF['Sales'].quantile(0.5) # get quantile deviation (50% quantile = median)\n",
    "iceDF['Sales'].cumsum()  # get cummulative sum of all the data in the Sales column\n",
    "iceDF['Sales'].cumprod() # get cummulative product of all the data in the sales column\n",
    "iceDF['Sales'].cummax()  # get cummulative sum until the cumsum values <= max value\n",
    "iceDF['Sales'].cummin()  # get cummulative sum until the cumsum values <= min value\n",
    "\n",
    "iceDF.describe()# get all the info about our Dataframe\n",
    "iceDF.describe()# get all the info about our Sales column4\n",
    "\n",
    "seriesDice = pd.Series(data=[2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, \n",
    "                           6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8,\n",
    "                          8, 8, 9, 9, 9, 9, 10, 10, 10, 11, 11, 12])\n",
    "# Count for each value in series\n",
    "seriesDice.value_counts()\n",
    "\n",
    "print(dataframe2)\n",
    "dataframe2.agg(np.mean) # get aggregate value\n",
    "dataframe2.agg(['mean', 'std']) # using multiple different functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-hunter",
   "metadata": {},
   "source": [
    "### Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dominant-roberts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    C   D   E\n",
      "B  42  40  39\n",
      "C  35  27  14\n",
      "Pandas(Index='B', C=42, D=40, E=39)\n",
      "Pandas(Index='C', C=35, D=27, E=14)\n"
     ]
    }
   ],
   "source": [
    "# Iterating over series\n",
    "series_7 = pd.Series(range(5), index=['a', 'b', 'c', 'd', 'e'])\n",
    "for col in series_7:\n",
    "#     print(col)\n",
    "    pass\n",
    "    \n",
    "\n",
    "# Iterating over DFs\n",
    "array4 = np.random.randint(10, 50, size=(2, 3))\n",
    "dataframe16 = pd.DataFrame(array4, ['B', 'C'], ['C', 'D', 'E'])\n",
    "print(dataframe16)\n",
    "\n",
    "# iterate through columns\n",
    "for label, series in dataframe16.items():\n",
    "#     print(label)  # prints individual column index\n",
    "#     print(series) # prints all row value of each column (label) \n",
    "    pass\n",
    "\n",
    "# iterate through rows\n",
    "for index, row in dataframe16.iterrows():\n",
    "#     print(f'{index}\\n{row}') # index prints row & 'row' print the column values in each row(index)\n",
    "    pass\n",
    "\n",
    "# get tuple that contains our row data\n",
    "for row in dataframe16.itertuples():\n",
    "    print(row) # gives row data (index=row name; C, D, E = column value in this row)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-camera",
   "metadata": {},
   "source": [
    "### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "technical-uniform",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    C   D   E\n",
      "B  42  40  39\n",
      "C  35  27  14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C   D   E\n",
       "C  35  27  14\n",
       "B  42  40  39"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataframe16)\n",
    "\n",
    "# sort dataframe according to row/index\n",
    "dataframe16.sort_index()                # ascending order\n",
    "dataframe16.sort_index(ascending=False) # descending order\n",
    "\n",
    "# sort dataframe according to column/label/value\n",
    "dataframe16.sort_values(by='D') # sort according to data in column 'D' in ascending order\n",
    "# (Use the same function for series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-regulation",
   "metadata": {},
   "source": [
    "### Passing Data to Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "educational-growth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Profit: 5459.010000000001\n"
     ]
    }
   ],
   "source": [
    "# get data from a csv file\n",
    "csDF = pd.read_csv('ComputerSales.csv')\n",
    "\n",
    "# Get Total Profit from the dataframe that we imported from a csv file\n",
    "def profit_total(dataframe):\n",
    "    profit_series = dataframe['Profit']\n",
    "    print(f'Total Profit: {profit_series.sum()}')\n",
    "    \n",
    "profit_total(csDF)\n",
    "\n",
    "\n",
    "# get contact column and split first and last name and store them in two new columns\n",
    "def split_contact(dataframe):\n",
    "    \n",
    "    names = dataframe['Contact'].apply(get_names)\n",
    "    # apply get_names function to all the names(rows) in 'Contact' column\n",
    "    # apply passes contact name from each individual row to get_names function \n",
    "    # and store the result (dataframe of first name, and last name to 'names' variable)\n",
    "    \n",
    "    dataframe[names.columns] = names\n",
    "    # here names.columns are ['First Name', 'Last Name'] there are the columns of the dataframe\n",
    "    # set from the get_names function\n",
    "    # RHS names are the splitted names of the respective Contacts\n",
    "    # the splitted names are assigned to each respective rows\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def get_names(full_name):\n",
    "    first, last = full_name.split()\n",
    "    \n",
    "    return pd.Series(\n",
    "            (first, last),\n",
    "            index=['First Name', 'Last Name'])\n",
    "\n",
    "# split_contact(csDF)\n",
    "\n",
    "\n",
    "\n",
    "# assign people to different age groups\n",
    "def age_group(dataframe):\n",
    "    bins = [0, 30, 50, sys.maxsize] # these are age classes (0-30, 30-50, 50-maxAge)\n",
    "    labels = ['<30', '30-50', '>50']\n",
    "    ageGroup = pd.cut(dataframe['Age'], bins=bins, labels=labels)\n",
    "    # cut = puts values into certain groups based on interval\n",
    "    \n",
    "    # create new column and return the new data \n",
    "    dataframe['Age Group'] = ageGroup\n",
    "    return dataframe\n",
    "\n",
    "# age_group(csDF)\n",
    "\n",
    "\n",
    "\n",
    "# pass dataframe to multiple different functions\n",
    "newDF = csDF.pipe(split_contact).pipe(age_group)\n",
    "newDF.to_excel('test.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-laser",
   "metadata": {},
   "source": [
    "### Aligning, Reindexing & Renaming Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "blind-kenya",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    C   D   E\n",
      "A  49  24  31\n",
      "B  34  18  29\n",
      "    C   D   E\n",
      "B  49  24  31\n",
      "C  34  18  29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Married</th>\n",
       "      <td>49</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unmarried</th>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Men  Women  Others\n",
       "Married     49     24      31\n",
       "Unmarried   34     18      29"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------Align----------------------------------\n",
    "\n",
    "# aligning series\n",
    "series_8 = pd.Series(range(5), index=['a', 'b', 'c', 'd', 'e'])\n",
    "slice1 = series_8[:4]\n",
    "slice2 = series_8[1:]\n",
    "\n",
    "slice1.align(slice2, join='left')  # align based on the values in slice1\n",
    "slice1.align(slice2, join='right') # align based on the values in slice2\n",
    "slice1.align(slice2, join='inner') # align based on the intersection values\n",
    "slice1.align(slice2, join='outer') # align based on the union of the values\n",
    "slice1.align(slice2)               # another way of aligning based on union\n",
    "\n",
    "# aligning dataframes\n",
    "array5 = np.random.randint(10, 50, size=(2, 3))\n",
    "dataframe17 = pd.DataFrame(array5, ['A', 'B'], ['C', 'D', 'E'])\n",
    "dataframe18 = pd.DataFrame(array5, ['B', 'C'], ['C', 'D', 'E'])\n",
    "\n",
    "print(dataframe17)\n",
    "print(dataframe18)\n",
    "\n",
    "dataframe17.align(dataframe18) # union\n",
    "# just like in series, we can use join=['outer', 'inner', 'right', 'left']\n",
    "\n",
    "\n",
    "# ------------------------Reindex-------------------------\n",
    "series_8.reindex(['c', 'b', 'a']) # changing the rows of the series using index\n",
    "dataframe17.reindex(['B', 'A'])   # changing the rows of the dataframe using index\n",
    "\n",
    "dataframe17.drop(['B'], axis=0)      # remove row B\n",
    "dataframe17.drop(['D'], axis=1)      # remove column D\n",
    "dataframe17.drop(['D', 'E'], axis=1) # remove multiple columns\n",
    "\n",
    "\n",
    "# ---------------------Rename Labels----------------------------\n",
    "# renaming columns\n",
    "dataframe17.rename(columns={'C': 'Men', 'D': 'Women', 'E': 'Others'}, inplace=True)\n",
    "\n",
    "# renaming rows\n",
    "dataframe17.rename(index={'A': 'Married', 'B': 'Unmarried'}, inplace=True)\n",
    "\n",
    "# key=old column label, value=new column label\n",
    "# can be done with single or multiple labels\n",
    "# inplace=True: to change the dataframe permanently\n",
    "\n",
    "dataframe17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-ferry",
   "metadata": {},
   "source": [
    "### Multi-Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "mechanical-diagram",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Day 1</th>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Day 2</th>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "C        Female  Male\n",
       "A     B              \n",
       "Day 1 1     NaN   1.0\n",
       "      2     2.0   NaN\n",
       "      3     NaN   3.0\n",
       "Day 2 1     4.0   NaN\n",
       "      2     NaN   5.0\n",
       "      3     6.0   NaN"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multi-level indexing is going to allow us to store data on multiple different dimensions\n",
    "\n",
    "days = ['Day 1', 'Day 1', 'Day 1', 'Day 2', 'Day 2', 'Day 2']\n",
    "# three day 1s abd day 2s because people have three meals per day\n",
    "meals = [1, 2, 3, 1, 2, 3] \n",
    "# duplicate data are for the same reason as above\n",
    "\n",
    "# hierarchy index\n",
    "hierIndex = list(zip(days, meals))\n",
    "# zip: pairs our days to meals array and create list of the returned tuples\n",
    "\n",
    "\n",
    "# convert our list of tuple into each rows\n",
    "hierIndex = pd.MultiIndex.from_tuples(hierIndex)\n",
    "\n",
    "# create a random array to put as data in the MultiIndex data structure(dataframe)\n",
    "# the data represent calories of food eaten by males and females during thier 3 meal period\n",
    "# for 2 whole days\n",
    "array6 = np.random.randint(500, 700, size=(6, 2))\n",
    "\n",
    "# create dataframe with hierIndex as the labels and array6 as their data\n",
    "# here the heirIndex wont be used for columns so we need to assign columns manually\n",
    "dataframe19 = pd.DataFrame(array6, hierIndex, ['Male', 'Female'])\n",
    "# print(dataframe19)\n",
    "\n",
    "##################################################\n",
    "# to assign rows and columns from the hierIndex,\n",
    "# first change the array6 size to (6, 6) and use the code below\n",
    "# cols = [x[0] for x in hierIndex]\n",
    "# rows = [x[1] for x in hierIndex]\n",
    "# dataframe19 = pd.DataFrame(array6, rows, cols)\n",
    "# dataframe19\n",
    "##################################################\n",
    "\n",
    "# find out the data of day 1\n",
    "dataframe19.loc['Day 1']\n",
    "\n",
    "# grab first row as a series\n",
    "dataframe19.loc['Day 1'].loc[1]\n",
    "dataframe19.iloc[0] # another way of doing it\n",
    "\n",
    "# grab calories eaten by female on day 2 for the second meal\n",
    "dataframe19.loc['Day 2'].loc[2]['Female']\n",
    "dataframe19.iloc[4][1] # another way of doing it\n",
    "\n",
    "# assign names to day as well as meals columns\n",
    "dataframe19.index.names = ['Day', 'Meals']\n",
    "dataframe19\n",
    "\n",
    "# cross-section of Day 2 \n",
    "dataframe19.xs('Day 2') # returns a sub-table of the info about Day 2 only\n",
    "\n",
    "# get data of the 1st meal from both days\n",
    "dataframe19.xs(1, level='Meals')\n",
    "\n",
    "\n",
    "# Create a MultiIndex out of a DF using a pivot table\n",
    "# specially used with microsoft excel\n",
    "dict_6 = {'A':['Day 1', 'Day 1', 'Day 1', 'Day 2', 'Day 2', 'Day 2'],\n",
    "         'B': [1, 2, 3, 1, 2, 3],\n",
    "         'C': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female'],\n",
    "         'D': [1, 2, 3, 4, 5, 6]}\n",
    "dataframe20 = pd.DataFrame(dict_6)\n",
    "dataframe20.pivot_table(values='D', index=['A', 'B'], columns=['C'])\n",
    "\n",
    "# columns=['C] i.e ['Male, 'Female'] becomes the main column\n",
    "# Make A & B a multilevel index (rows)\n",
    "# Define column names come from column C\n",
    "# values='D'are data in the data set\n",
    "# You will have NaNs where data was missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-treasurer",
   "metadata": {},
   "source": [
    "### Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "rising-horizontal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B  C\n",
      "0  1.0  4.0  7\n",
      "1  2.0  NaN  8\n",
      "2  NaN  NaN  9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B  C\n",
       "0  1.0  4.0  7\n",
       "1  2.0  4.0  8\n",
       "2  2.0  4.0  9"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_7 = {'A': [1, 2, np.nan], 'B': [4, np.nan, np.nan], 'C': [7, 8, 9]}\n",
    "dataframe21 = pd.DataFrame(dict_7)\n",
    "print(dataframe21)\n",
    "\n",
    "# drop rows with missiong data \n",
    "dataframe21.dropna() # drops rows which contains atleast 1 NaN values\n",
    "\n",
    "# drop columns with missing data\n",
    "dataframe21.dropna(axis=1) # drops columns which contains atleast 1 NaN values\n",
    "\n",
    "# drop row which donot have atleast two non NaN values\n",
    "dataframe21.dropna(thresh=2)\n",
    "\n",
    "# fill NaN values\n",
    "dataframe21.fillna(value='newValue') # fill a string\n",
    "dataframe21.fillna(value=69)         # fill an integer\n",
    "\n",
    "# fill with the mean value of the data in the column\n",
    "dataframe21.fillna(value=dataframe21['A'].mean())\n",
    "\n",
    "# fill with the previous row value (the value from the row above the NaN value)\n",
    "dataframe21.fillna(method='ffill')\n",
    "# to fill with next row value, method='bfill'\n",
    "# in this dataframe, the row 2 doesnt have a row below it, \n",
    "# so using bfill wont change the NaN value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-dressing",
   "metadata": {},
   "source": [
    "### Experimenting with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "virtual-conclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sale ID', 'Contact', 'Sex', 'Age', 'State', 'Product ID',\n",
      "       'Product Type', 'Sale Price', 'Profit', 'Lead', 'Month', 'Year'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    35\n",
       "True      4\n",
       "Name: Profit, dtype: int64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data from a csv file\n",
    "csDF = pd.read_csv('ComputerSales.csv')\n",
    "\n",
    "# get all column names\n",
    "print(csDF.columns)\n",
    "\n",
    "# get all datas\n",
    "csDF.values\n",
    "\n",
    "# get Profit mean\n",
    "csDF['Profit'].mean()\n",
    "\n",
    "# get Product ID with the highest profit\n",
    "csDF[ ['Product ID', 'Profit'] ].max(axis=0)\n",
    "\n",
    "# find the data of the people who made purchases from West Virginia\n",
    "csDF[ csDF['State']=='WV' ]\n",
    "\n",
    "# find the no of people who made purchases from West Virginia\n",
    "csDF[ csDF['State']=='WV' ]['State'].count()\n",
    "\n",
    "# find the no of purchases in 2019\n",
    "len( csDF[ csDF['Year']==2019 ].index )\n",
    "\n",
    "# get no of sales for each product type\n",
    "csDF['Product ID'].value_counts()\n",
    "\n",
    "# get list of customers that bought a specific product\n",
    "csDF[ csDF['Product ID']=='M01-F0024' ]['Contact']\n",
    "\n",
    "# find out how many people made purchase from the website for a profit over $150\n",
    "csDF[ (csDF['Lead']=='Website') & (csDF['Profit']>150) ]['Lead'].count()\n",
    "\n",
    "# find out how many product profit amounts include .89 in cents\n",
    "csDF['Profit'].apply( lambda cents: str(cents).split('.')[1]=='89' ).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-cosmetic",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "fancy-still",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Pie'>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "# displays plots in the notebook\n",
    "\n",
    "# ---------------------------Histogram----------------------------\n",
    "# It provides an approximation of the distribution of results. \n",
    "# create them by dividing the range of values into bins or buckets. (classes) \n",
    "# Then you count how many of the results fall into each bin.\n",
    "# Rolls 2 dice 5000 times and charts the frequency and a histogram\n",
    "\n",
    "# Even though the odds increase as you approach 7 and then decrease again \n",
    "# 1 way to roll a 2: (1, 1)\n",
    "# 6 ways to roll a 7: [(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)] \n",
    "# and again 1 way to roll a 12: (6, 6)\n",
    "# each tuple represents the result in two different dices\n",
    "# over many rolls they are nearly equal.\n",
    "diceDF = pd.DataFrame(\n",
    "        np.random.randint(1, 7, 5000),\n",
    "        columns=['Hist'])\n",
    "\n",
    "diceDF['Odds'] = diceDF['Hist'] + np.random.randint(1, 7, 5000)\n",
    "\n",
    "# diceDF.plot.hist(bins=12, alpha=0.5)\n",
    "# bins=12, 12 different ways of rolling the dice, the result are stored in these bins(classes)\n",
    "# alpha: opacity\n",
    "\n",
    "\n",
    "# --------------------------Line PLot--------------------------------\n",
    "series_9 = pd.Series(np.random.randn(1000),\n",
    "                 index=pd.date_range('11/15/2017', periods=1000))\n",
    "series_9 = series_9.cumsum()\n",
    "# series_9.plot()\n",
    "\n",
    "# Basic plot using 3 different data with\n",
    "# 1000 random values that create cumulative sums over an increasing date range\n",
    "dataframe22 = pd.DataFrame(np.random.randn(1000, 3), \n",
    "                     index=pd.date_range('11/15/2017', \n",
    "                     periods=1000),\n",
    "                     columns=list('ABC'))\n",
    "dataframe22 = dataframe22.cumsum()\n",
    "# dataframe22.plot()\n",
    "\n",
    "\n",
    "# -------------------------Bar Chart-------------------------\n",
    "# pd.DataFrame(np.random.randn(5)).plot.bar()\n",
    "\n",
    "# multiple bar charts\n",
    "vals = ['A', 'B', 'C', 'D']\n",
    "dataframe23 = pd.DataFrame(np.random.randn(10, 4), columns=vals)\n",
    "# dataframe23.plot.bar()\n",
    "# create 10 arrays conatining 4 random values\n",
    "\n",
    "\n",
    "# ------------------------Area Plot-----------------------------\n",
    "\n",
    "xVals = range(1, 15)\n",
    "yVals = [1,5,4,7,6,9,5,7,10,14,10,12,9,8]\n",
    "\n",
    "# plt.fill_between(xVals, yVals, color='skyblue', alpha=0.5)\n",
    "# plt.show()\n",
    "\n",
    "# area plot with multiple areas\n",
    "# pd.DataFrame(np.random.rand(10, 3), columns=['A', 'B', 'C']).plot.area()\n",
    "\n",
    "\n",
    "# ----------------------Scatter PLot-----------------------------\n",
    "# Create a scatterplot with 100 random values\n",
    "# pd.DataFrame(np.random.rand(100, 2), columns=['A', 'B']).plot.scatter(x='A', y='B')\n",
    "\n",
    "# Multiple column scatter plots\n",
    "dataframe23 = pd.DataFrame(np.random.rand(50, 4), columns=['A', 'B', 'C', 'D'])\n",
    "# ax = dataframe23.plot.scatter(x='A', y='B', color='DarkBlue', label='Group 1')\n",
    "# dataframe23.plot.scatter(x='C', y='D', color='Orange', label='Group 2', ax=ax)\n",
    "\n",
    "\n",
    "# --------------------------Pie Chart------------------------------\n",
    "pd.Series(np.random.rand(4), index=['a', 'b', 'c', 'd'], name='Pie').plot.pie(figsize=(6, 6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
